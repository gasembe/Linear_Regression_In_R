summary(ModelCars22)
#Adjusted R-squared:  0.9571
# Companydodge has the highest p value 0.034691, remove it
ModelCars23 = lm(formula =  price ~ aspiration + enginelocation + carwidth   +
enginesize + stroke + peakrpm + Companybmw +
Companybuick   + Companyjaguar + Companymitsubishi  + Companysubaru    +
drivewheelrwd + enginetyperotor, data = TrainPrices)
summary(ModelCars23)
#Adjusted R-squared:  0.9559
# drivewheelrwd  has highest p-value, we remove it
ModelCars24 = lm(formula =  price ~ aspiration + enginelocation + carwidth   +
enginesize + stroke + peakrpm + Companybmw +
Companybuick   + Companyjaguar + Companymitsubishi  + Companysubaru    +
enginetyperotor, data = TrainPrices)
summary(ModelCars24)
#Adjusted R-squared:  0.9539
# Companymitsubishi has highest p value , we remove it
ModelCars25 = lm(formula =  price ~ aspiration + enginelocation + carwidth   +
enginesize + stroke + peakrpm + Companybmw + Companybuick   + Companyjaguar   + Companysubaru    +
enginetyperotor, data = TrainPrices)
summary(ModelCars25)
#Adjusted R-squared:  0.9514
# All variables have a small p vallue of ***
vif(ModelCars25)
# enginesize has a vif of 5.2, highest among the variables left, however removing it drastically reduces
# the adjusted R-squared from 0.9514 to 0.8966  and a number of variables become insignificant. Due to this we can't
# reduce the variables any further.
# Therefore we conclude at ModelCars25 as the best possible model
# MODEL TESTING
# Predict price using TestPrice dataset earlier extracted, exclude price colum from the data set
predicted_priced <-  predict(ModelCars25, subset(TestPrices, select= -c(price)))
# Bind the predicted values to the data set
TestPrices$predicted_price <- predicted_priced
Rcor <- cor(TestPrices$price,TestPrices$predicted_price)
# Actual Price and predicted price have a strong correlation of 0.91
R_squared <- Rcor^2
R_squared
# CONCLUSION
# ModelCars25 is the model to help Geely Auto to understand the factors affecting the pricing of cars in the American marketing.
# The model can explain 83.46% of the variability of the data as obtained from R_squared above .
# Data understanding
str(CarPrices)
# Useful libraryies for the project
#--------------------------------------------------------------------------------
library(stringr)
library(tidyverse)
library(lubridate)
library(plyr)
library(lubridate)
# Data sourcing
#-----------------------------------------------------------------------------------
bi_chats <- read.delim("bi_chatsv.txt", header = FALSE, sep ="-" )
#Multiple Linear Regression
advertisement<-read.csv("advertising.csv")
#Examine the data
View(advertisement)
#Importing dataset in R
advertising <- read.csv("tvmarketing.csv")
View(advertising)
# Let's quickly look at the plot of sales and TV spend
plot(advertising$TV, advertising$Sales)
View(advertising)
### So set the seed to 100, let's run it
set.seed(100)
trainindices= sample(1:nrow(advertising), 0.7*nrow(advertising))
train.advertising = advertising[trainindices,]
test = advertising[-trainindices,]
model<-lm(Sales~TV,data = train.advertising)
summary(model)
# Now, execute this command
Predict_1 <- predict(model, test[-2])
test$test_sales <- Predict_1
r <- cor(test$Sales,test$test_sales)
rsquared <- r^2
rsquared
#Multiple Linear Regression
advertisement<-read.csv("advertising.csv")
#Examine the data
View(advertisement)
# Check the structure of "advertisement"
str(advertisement)
# Now first build the linear model using lm() and store it into a object "model_1"
model_1 <- lm(Sales~.,data=advertisement)
#Now, check the summary of your first model i.e model_1
summary(model_1)
# Compare simple model with Newspaper with the MLR model:
# Create a Simple Linear Regression model where Sales is the independent variable and Newspaper the only independent variable
news_model <- lm(Sales~Newspaper, advertisement)
# Check the summary of both the models
summary(news_model)
summary(model_1)
# Look at the correlations between the independent variables.
corrs = cor(advertisement[, -4])
View(round(corrs, 2))
# Remove the Newspaper variable, as it was insignificant in the multiple variable model
# Store the new linear model having TV and Radio marketing as the two significant variables into the object "model_2" .
model_2 <- lm(Sales~.-Newspaper,data=advertisement)
# Great! Check the summary of model_2
summary(model_2)
housing <- read.csv("Housing.csv")
View(housing)
str(housing)
# convert factors with 2 levels to numerical variables
levels(housing$mainroad)<-c(1,0)
housing$mainroad<- as.numeric(levels(housing$mainroad))[housing$mainroad]
levels(housing$guestroom)<-c(1,0)
housing$guestroom <- as.numeric(levels(housing$guestroom))[housing$guestroom]
levels(housing$basement)<-c(1,0)
housing$basement <- as.numeric(levels(housing$basement))[housing$basement]
levels(housing$hotwaterheating)<-c(1,0)
housing$hotwaterheating <- as.numeric(levels(housing$hotwaterheating))[housing$hotwaterheating]
levels(housing$airconditioning)<-c(1,0)
housing$airconditioning <- as.numeric(levels(housing$airconditioning))[housing$airconditioning]
levels(housing$prefarea)<-c(1,0)
housing$prefarea <- as.numeric(levels(housing$prefarea))[housing$prefarea]
# Now we come across variables having more than 3 levels.
summary(factor(housing$furnishingstatus))
#Converting "furnishingstatus" into dummies .
dummy_1 <- data.frame(model.matrix( ~furnishingstatus, data = housing))
#check the dummy_1 data frame.
View(dummy_1)
dummy_1 <- dummy_1[,-1]
# Combine the dummy variables and the numeric columns of housing dataset, in a new dataset called housing_1
housing_1 <- cbind(housing[,-13], dummy_1)
# create derived metrics
# create a new metric area per unit bedrooms
housing_1$areaperbedroom <- housing_1$area/housing_1$bedrooms
# create a new metric bathrooms per bedrooms
housing_1$bbratio <- housing_1$bathrooms/housing_1$bedrooms
View(housing_1)
# Divide into training and test data set
#set the seed to 100, let's run it
set.seed(100)
# randomly generate row indices for train dataset
trainindices= sample(1:nrow(housing_1), 0.7*nrow(housing_1))
# generate the train data set
train = housing_1[trainindices,]
#Similarly store the rest of the observations into an object "test".
test = housing_1[-trainindices,]
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(price~.,data=train)
# Check the summary of model.
summary(model_1)
# Check if the correlation matrix givessome insight.
corrs = cor(housing_1)
View(corrs)
# load the package
library("car")
# Pass the model_1 in the vif function
vif(model_1)
# Look at summary of the model again to see the P values
summary(model_1)
# Look at summary of the model again to see the P values
summary(model_1)
# Pass the model_1 in the vif function
vif(model_1)
model_2 <- lm(formula = price ~ area + bedrooms + bathrooms + stories + mainroad + guestroom +
basement + hotwaterheating + airconditioning + parking + prefarea +
furnishingstatusunfurnished + furnishingstatussemi.furnished + areaperbedroom, data = train)
# check the accuracy of this model
summary(model_2)
# Repeat the process of vif calculation of model_2.
vif(model_2)
# Remove the areaperbedroom variable based on high VIF and insignificance (p>0.05)
# Make a model without areaperbedroom variable
model_3 <- lm(formula = price ~ area + bedrooms + bathrooms + stories + mainroad + guestroom +
basement + hotwaterheating + airconditioning + parking + prefarea +
furnishingstatusunfurnished + furnishingstatussemi.furnished , data = train)
#Check the accuracy of this model
summary(model_3)
# Calculate the vif for model_3.
vif(model_3)
model_4 <- lm(formula = price ~ area + bedrooms + bathrooms + stories + mainroad + guestroom +
basement + hotwaterheating + airconditioning + parking + prefarea +
furnishingstatusunfurnished , data = train)
# Check the accuracy and p-values again
summary(model_4)
model_5 <- lm(formula = price ~ area + bathrooms + stories + mainroad + guestroom +
basement + hotwaterheating + airconditioning + parking + prefarea +
furnishingstatusunfurnished , data = train)
### Check the accuracy and p-values again
summary(model_5)
model_6 <- lm(formula = price ~ area + bathrooms + stories + mainroad + guestroom +
hotwaterheating + airconditioning + parking + prefarea +
furnishingstatusunfurnished , data = train)
### Check the accuracy and p-values again
summary(model_6)
model_7 <- lm(formula = price ~ area + bathrooms + stories + guestroom +
hotwaterheating + airconditioning + parking + prefarea +
furnishingstatusunfurnished , data = train)
# Check the adjusted R-squared and p-values again
summary(model_7)
model_8 <- lm(formula = price ~ area + bathrooms + stories + guestroom +
airconditioning + parking + prefarea +
furnishingstatusunfurnished , data = train)
#Check the accuracy
summary(model_8)
# Predict the house prices in the testing dataset
Predict_1 <- predict(model_8,test[,-1])
test$test_price <- Predict_1
# Accuracy of the predictions
# Calculate correlation
r <- cor(test$price,test$test_price)
# calculate R squared by squaring correlation
rsquared <- cor(test$price,test$test_price)^2
# check R-squared
rsquared
r
View(test)
onecor = cor(1,1)
onecor
onecor = cor(c(1,2,3,4,5),c(1,2,3,4,5))
onecor
housing <- read.csv("Housing.csv")
View(housing)
str(housing)
# Here we follow the same steps as we did in the previous case.
# convert factors with 2 levels to numerical variables
levels(housing$mainroad)<-c(1,0)
housing$mainroad<- as.numeric(levels(housing$mainroad))[housing$mainroad]
levels(housing$guestroom)<-c(1,0)
housing$guestroom <- as.numeric(levels(housing$guestroom))[housing$guestroom]
levels(housing$basement)<-c(1,0)
housing$basement <- as.numeric(levels(housing$basement))[housing$basement]
levels(housing$hotwaterheating)<-c(1,0)
housing$hotwaterheating <- as.numeric(levels(housing$hotwaterheating))[housing$hotwaterheating]
levels(housing$airconditioning)<-c(1,0)
housing$airconditioning <- as.numeric(levels(housing$airconditioning))[housing$airconditioning]
levels(housing$prefarea)<-c(1,0)
housing$prefarea <- as.numeric(levels(housing$prefarea))[housing$prefarea]
# Create the dummy variable for furnishingstatus variable
dummy_1 <- data.frame(model.matrix( ~furnishingstatus, data = housing))
View(dummy_1)
dummy_1 <- dummy_1[,-1]
# Combine the dummy variables and the numeric columns of housing dataset, in a new dataset called housing_1
housing_1 <- cbind(housing[,-13], dummy_1)
# create derived metrics
# create a new metric area per unit bedrooms
housing_1$areaperbedroom <- housing_1$area/housing_1$bedrooms
# create a new metric bathrooms per bedrooms
housing_1$bbratio <- housing_1$bathrooms/housing_1$bedrooms
# separate training and testing data
set.seed(100)
trainindices= sample(1:nrow(housing_1), 0.7*nrow(housing_1))
train = housing_1[trainindices,]
test = housing_1[-trainindices,]
# Build model 1 containing all variables
model_1 <-lm(price~.,data=train)
summary(model_1)
#######
library(MASS)
step <- stepAIC(model_1, direction="both")
# Let's execute this model here,
model_2 <- lm(formula = price ~ area + bathrooms + stories + mainroad +
guestroom + basement + hotwaterheating + airconditioning +
parking + prefarea + furnishingstatusunfurnished + areaperbedroom,
data = train)
# Let us look at the summary of the model
summary(model_2)
## Let us check for multicollinearity
# If the VIF is above 2 or 5 as the business goal says, you would remove
# the variables if they are statistically insignificant
vif(model_2)
model_3 <- lm(formula = price ~ area + bathrooms + stories + mainroad +
guestroom + basement + hotwaterheating + airconditioning +
parking + prefarea + furnishingstatusunfurnished,
data = train)
# Let us look at the VIFs now
vif(model_3)
# All variables have a VIF below 2
# Let us check now for variables which have high p values
summary(model_3)
model_4 <- lm(formula = price ~ area + bathrooms + stories + mainroad +
guestroom + hotwaterheating + airconditioning +
parking + prefarea + furnishingstatusunfurnished,
data = train)
summary(model_4)
model_4 <- lm(formula = price ~ area + bathrooms + stories +
guestroom + hotwaterheating + airconditioning +
parking + prefarea + furnishingstatusunfurnished,
data = train)
summary(model_4)
# Remove hotwaterheating
model_5 <- lm(formula = price ~ area + bathrooms + stories +
guestroom + airconditioning +
parking + prefarea + furnishingstatusunfurnished,
data = train)
summary(model_5)
# predicting the results in test dataset
Predict_1 <- predict(model_5,test[,-1])
test$test_price <- Predict_1
# Now, we need to test the r square between actual and predicted sales.
r <- cor(test$price,test$test_price)
rsquared <- cor(test$price,test$test_price)^2
rsquared
housing <- read.csv("Housing.csv")
View(housing)
#DUMMY VARIABLE CREATION.
#Let us see the structure of variable "mainroad".
str(housing$mainroad)
#DUMMY VARIABLE CREATION.
#Let us see the structure of variable "mainroad".
str(housing$mainroad)
summary(factor(housing$mainroad))
# One simple way to convert mainroad variable to numeric is to replace the levels- Yes's and Nos's with 1 and 0 is:
levels(housing$mainroad)<-c(1,0)
# Now store the numeric values in the same variable
housing$mainroad<- as.numeric(levels(housing$mainroad))[housing$mainroad]
# Check the summary of mainroad variable
summary(housing$mainroad)
# Do the same for other such categorical variables
levels(housing$guestroom)<-c(1,0)
housing$guestroom <- as.numeric(levels(housing$guestroom))[housing$guestroom]
levels(housing$basement)<-c(1,0)
housing$basement <- as.numeric(levels(housing$basement))[housing$basement]
levels(housing$hotwaterheating)<-c(1,0)
housing$hotwaterheating <- as.numeric(levels(housing$hotwaterheating))[housing$hotwaterheating]
levels(housing$airconditioning)<-c(1,0)
housing$airconditioning <- as.numeric(levels(housing$airconditioning))[housing$airconditioning]
levels(housing$prefarea)<-c(1,0)
housing$prefarea <- as.numeric(levels(housing$prefarea))[housing$prefarea]
# Now we come across variables having more than 3 levels.
summary(factor(housing$furnishingstatus))
#Converting "furnishingstatus" into dummies .
dummy_1 <- data.frame(model.matrix( ~furnishingstatus, data = housing))
#check the dummy_1 data frame.
View(dummy_1)
#Linear Regression Model
housing <- read.csv("Housing.csv")
View(housing)
# datadictonary
# price represents the sale price of a house in Rs.
# area gives the total size of a property in square feet
# bedrooms represents the number of bedrooms
# bathrooms shows the number of bathrooms
# stories variable shows the number of stories excluding basement
# mainroad =1 if the house faces a main road
# livingroom   = 1 if the house has a separate living room or a drawing room for guests
# basement shows if the house has a basement
# hotwaterheating  = 1 if the house uses gas for hot water heating
# airconditioning    = 1 if there is central air conditioning
# parking shoes the number of cars that can be parked
# prefarea is 1 if the house is located in the preferred neighbourhood of the city
#Let us examine the structure of the dataset
str(housing)
#DUMMY VARIABLE CREATION.
#Let us see the structure of variable "mainroad".
str(housing$mainroad)
summary(factor(housing$mainroad))
# One simple way to convert mainroad variable to numeric is to replace the levels- Yes's and Nos's with 1 and 0 is:
levels(housing$mainroad)<-c(1,0)
# Now store the numeric values in the same variable
housing$mainroad<- as.numeric(levels(housing$mainroad))[housing$mainroad]
# Check the summary of mainroad variable
summary(housing$mainroad)
# Do the same for other such categorical variables
levels(housing$guestroom)<-c(1,0)
housing$guestroom <- as.numeric(levels(housing$guestroom))[housing$guestroom]
levels(housing$basement)<-c(1,0)
housing$basement <- as.numeric(levels(housing$basement))[housing$basement]
levels(housing$hotwaterheating)<-c(1,0)
housing$hotwaterheating <- as.numeric(levels(housing$hotwaterheating))[housing$hotwaterheating]
levels(housing$airconditioning)<-c(1,0)
housing$airconditioning <- as.numeric(levels(housing$airconditioning))[housing$airconditioning]
levels(housing$prefarea)<-c(1,0)
housing$prefarea <- as.numeric(levels(housing$prefarea))[housing$prefarea]
# Now we come across variables having more than 3 levels.
summary(factor(housing$furnishingstatus))
#Converting "furnishingstatus" into dummies .
dummy_1 <- data.frame(model.matrix( ~furnishingstatus, data = housing))
#check the dummy_1 data frame.
View(dummy_1)
#This column should be removed from the newly created dummy_1 dataframe containing the dummy values for the variable "fusrnishingstatus".
dummy_1 <- dummy_1[,-1]
# Combine the dummy variables to the main data set, after removing the original categorical "furnishingstatus" column
housing_1 <- cbind(housing[,-13], dummy_1)
View(housing_1)
##############
# Let us create the new metric and assign it to "areaperbedroom"
housing_1$areaperbedroom <- housing_1$area/housing_1$bedrooms
# metric - bathrooms per bedroom
housing_1$bbratio <- housing_1$bathrooms/housing_1$bedrooms
View(housing)
# Divide into training and test data set
#set the seed to 100, let's run it
set.seed(100)
# Divide into training and test data set
#set the seed to 100, let's run it
set.seed(100)
# randomly generate row indices for train dataset
trainindices= sample(1:nrow(housing_1), 0.7*nrow(housing_1))
# generate the train data set
train = housing_1[trainindices,]
#Similarly store the rest of the observations into an object "test".
test = housing_1[-trainindices,]
#Execute the first model_1 multilinear model in the training set.
model_1 <-lm(price~.,data=train)
# Check the summary of model.
summary(model_1)
# Check if the correlation matrix givessome insight.
corrs = cor(housing_1)
View(corrs)
install.packages("car")
# load the package
library("car")
# Pass the model_1 in the vif function
vif(model_1)
# load the package
library("car")
getwd()
#1Load data set
radioAds <- read.csv("radiomarketing.csv", header = TRUE, stringsAsFactors = FALSE)
#2 inspect structure of data set plot to see relationship
str(radioAds)
getwd()
#1Load data set
radioAds <- read.csv("radiomarketing.csv", header = TRUE, stringsAsFactors = FALSE)
#2 inspect structure of data set plot to see relationship
str(radioAds)
View(radioAds)
View(radioAds)
plot(radioAds$Radio, radioAds$Sales)
#3 set seed
set.seed(100)
?sample
#4 create training set
trainsample <- sample(1:nrow(radioAds), 0.7 * nrow(radioAds))
trainingSet <- radioAds[trainsample,]
# Create testing set
testSet <- radioAds[-trainsample,]
# Create model
radioModel <- lm(Radio~Sales, data = trainingSet)
summary(radioModel)
predicted_radio <- predict(radioModel, testSet[-2])
# attached predicted variables to the test set
testSet$Pred <- predicted_radio
#Store the mtcars data set in a variable, say cars.
cars <- mtcars
View(cars)
View(cars)
model_c <- lm(mpg~., data = cars)
summary(model_c)
set.seed(1:100)
rand <- sample(1:100, nrow(cars))
cars$rv <- rand
#Build another model to model mpg with all other variables including the randomly
model_r <- lm(mpg~., data = cars)
summary(model_r)
#Multiple Linear Regression
advertisement<-read.csv("advertising.csv")
#Examine the data
View(advertisement)
# Check the structure of "advertisement"
str(advertisement)
# Now first build the linear model using lm() and store it into a object "model_1"
model_1 <- lm(Sales~.,data=advertisement)
#Now, check the summary of your first model i.e model_1
summary(model_1)
# Compare simple model with Newspaper with the MLR model:
# Create a Simple Linear Regression model where Sales is the independent variable and Newspaper the only independent variable
news_model <- lm(Sales~Newspaper, advertisement)
# Check the summary of both the models
summary(news_model)
summary(model_1)
# Look at the correlations between the independent variables.
corrs = cor(advertisement[, -4])
View(round(corrs, 2))
# Remove the Newspaper variable, as it was insignificant in the multiple variable model
# Store the new linear model having TV and Radio marketing as the two significant variables into the object "model_2" .
model_2 <- lm(Sales~.-Newspaper,data=advertisement)
# Great! Check the summary of model_2
summary(model_2)
#setwd("C:/Users/aadam/OneDrive/PGDDS/Module 1 - Linear Regression")
setwd("C:/Users/HP/OneDrive/PGDDS/Module 1 - Linear Regression")
#setwd("C:/Users/aadam/OneDrive/PGDDS/Module 1 - Linear Regression")
setwd("E:/AA\OneDrive/PGDDS/Predictive Analytics I/Module 1 - Linear RegressionE:/AA/OneDrive/PGDDS/Predictive Analytics I/Module 1 - Linear Regression")
#setwd("C:/Users/aadam/OneDrive/PGDDS/Module 1 - Linear Regression")
setwd("E:/AA/OneDrive/PGDDS/Predictive Analytics I/Module 1 - Linear RegressionE:/AA/OneDrive/PGDDS/Predictive Analytics I/Module 1 - Linear Regression")
#setwd("C:/Users/aadam/OneDrive/PGDDS/Module 1 - Linear Regression")
setwd("E:/AA/OneDrive/PGDDS/Predictive Analytics I/Module 1 - Linear Regression")
housing <- read.csv("Housing.csv")
View(housing)
View(advertisement)
#setwd("C:/Users/aadam/OneDrive/PGDDS/Module 1 - Linear Regression")
setwd("E:/AA/OneDrive/PGDDS/Predictive Analytics I/Module 1 - Linear Regression")
housing <- read.csv("Housing.csv")
View(housing)
str(housing)
# convert factors with 2 levels to numerical variables
levels(housing$mainroad)<-c(1,0)
housing$mainroad<- as.numeric(levels(housing$mainroad))[housing$mainroad]
levels(housing$guestroom)<-c(1,0)
housing$guestroom <- as.numeric(levels(housing$guestroom))[housing$guestroom]
levels(housing$basement)<-c(1,0)
housing$basement <- as.numeric(levels(housing$basement))[housing$basement]
levels(housing$hotwaterheating)<-c(1,0)
housing$hotwaterheating <- as.numeric(levels(housing$hotwaterheating))[housing$hotwaterheating]
levels(housing$airconditioning)<-c(1,0)
housing$airconditioning <- as.numeric(levels(housing$airconditioning))[housing$airconditioning]
levels(housing$prefarea)<-c(1,0)
housing$prefarea <- as.numeric(levels(housing$prefarea))[housing$prefarea]
# Create the dummy variable for furnishingstatus variable
dummy_1 <- data.frame(model.matrix( ~furnishingstatus, data = housing))
View(dummy_1)
dummy_1 <- dummy_1[,-1]
# Combine the dummy variables and the numeric columns of housing dataset, in a new dataset called housing_1
housing_1 <- cbind(housing[,-13], dummy_1)
# create derived metrics
# create a new metric area per unit bedrooms
housing_1$areaperbedroom <- housing_1$area/housing_1$bedrooms
# create a new metric bathrooms per bedrooms
housing_1$bbratio <- housing_1$bathrooms/housing_1$bedrooms
